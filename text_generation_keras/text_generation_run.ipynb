{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported everything we need form Keras, we're all set to go!\n",
    "\n",
    "First, we load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data        = open(filename).read()\n",
    "    data        = data.lower()\n",
    "    \n",
    "    # Find all the unique characters\n",
    "    chars       = sorted(list(set(data)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    vocab_size  = len(chars)\n",
    "    \n",
    "    list_X      = []\n",
    "    list_Y      = []\n",
    "    # Python append is faster than numpy append\n",
    "    for i in range(0, len(data) - SEQ_LENGTH, 1):\n",
    "        seq_in  = data[i : i + SEQ_LENGTH]\n",
    "        seq_out = data[i + SEQ_LENGTH]\n",
    "        list_X.append([char_to_int[char] for char in seq_in])\n",
    "        list_Y.append(char_to_int[seq_out])\n",
    "    \n",
    "    n_patterns  = len(list_X)\n",
    "\n",
    "    X           = np.reshape(list_X, (n_patterns, SEQ_LENGTH, 1))\n",
    "\n",
    "    # Encode output as one-hot vector\n",
    "    Y           = np_utils.to_categorical(list_Y)\n",
    "\n",
    "    return X, Y, int_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions returns an array of sequences from the input text file and the corresponding output for each sequence encoded as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add a function to create our LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(n_hidden_layers, input_shape, hidden_dim, n_out, **kwargs):\n",
    "    drop        = kwargs.get('drop_rate', 0.2)\n",
    "    activ       = kwargs.get('activation', 'softmax')\n",
    "    mode        = kwargs.get('mode', 'train')\n",
    "    hidden_dim  = int(hidden_dim)\n",
    "    model       = Sequential()\n",
    "    flag        = True\n",
    "\n",
    "    if (n_hidden_layers == 0):\n",
    "        flag = False\n",
    "    \n",
    "    model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2]), return_sequences = flag ) )\n",
    "    if mode == 'train':\n",
    "        model.add( Dropout(drop) )\n",
    "\n",
    "    for i in range(n_hidden_layers - 1):\n",
    "        model.add( LSTM(hidden_dim, return_sequences = True) )\n",
    "        if mode == 'train':\n",
    "            model.add( Dropout(drop) )\n",
    "\n",
    "    if (n_hidden_layers == 1):\n",
    "        model.add( LSTM(hidden_dim) )\n",
    "    if mode == 'train':\n",
    "        model.add( Dropout(drop) )\n",
    "\n",
    "    model.add( Dense(n_out, activation = activ) )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, X, Y, n_epochs, b_size, vocab_size, **kwargs):    \n",
    "    loss            = kwargs.get('loss', 'categorical_crossentropy')\n",
    "    opt             = kwargs.get('optimizer', 'adam')\n",
    "    \n",
    "    model.compile(loss = loss, optimizer = opt)\n",
    "\n",
    "    filepath        = \"Weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "    callbacks_list  = [checkpoint]\n",
    "    X               = X / float(vocab_size)\n",
    "    model.fit(X, Y, epochs = n_epochs, batch_size = b_size, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function will run the input batchwase n_epochs number of times and it will save the weights to a file whenever there is an improvement. This is taken care of through the callback. <br><br>\n",
    "After the training is done or once you find a loss that you are happy with, you can test how well the model generates text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, X, filename, ix_to_char, vocab_size):\n",
    "    \n",
    "    # Load the weights from the epoch with the least loss\n",
    "    model.load_weights(filename)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "    start   = np.random.randint(0, len(X) - 1)\n",
    "    pattern = np.ravel(X[start]).tolist()\n",
    "\n",
    "    # We seed the model with a random sequence of 100 so it can start predicting\n",
    "    print (\"Seed:\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in pattern]), \"\\\"\")\n",
    "    output = []\n",
    "    for i in range(250):\n",
    "        x           = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x           = x / float(vocab_size)\n",
    "        prediction  = model.predict(x, verbose = 0)\n",
    "        index       = np.argmax(prediction)\n",
    "        result      = index\n",
    "        output.append(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1 : len(pattern)]\n",
    "\n",
    "    print(\"Predictions\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in output]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to either train our test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "[[35]\n",
      " [17]\n",
      " [ 1]\n",
      " [31]\n",
      " [20]\n",
      " [27]\n",
      " [33]\n",
      " [24]\n",
      " [16]\n",
      " [ 1]\n",
      " [31]\n",
      " [32]\n",
      " [13]\n",
      " [30]\n",
      " [32]\n",
      " [ 1]\n",
      " [14]\n",
      " [13]\n",
      " [15]\n",
      " [23]\n",
      " [ 7]\n",
      " [ 1]\n",
      " [19]\n",
      " [13]\n",
      " [30]\n",
      " [17]\n",
      " [16]\n",
      " [ 1]\n",
      " [33]\n",
      " [30]\n",
      " [19]\n",
      " [17]\n",
      " [16]\n",
      " [ 1]\n",
      " [13]\n",
      " [31]\n",
      " [ 1]\n",
      " [32]\n",
      " [20]\n",
      " [17]\n",
      " [ 1]\n",
      " [35]\n",
      " [27]\n",
      " [27]\n",
      " [16]\n",
      " [31]\n",
      " [ 1]\n",
      " [14]\n",
      " [17]\n",
      " [19]\n",
      " [13]\n",
      " [26]\n",
      " [ 1]\n",
      " [32]\n",
      " [27]\n",
      " [ 1]\n",
      " [19]\n",
      " [30]\n",
      " [27]\n",
      " [35]\n",
      " [ 1]\n",
      " [16]\n",
      " [13]\n",
      " [30]\n",
      " [23]\n",
      " [ 1]\n",
      " [13]\n",
      " [30]\n",
      " [27]\n",
      " [33]\n",
      " [26]\n",
      " [16]\n",
      " [ 1]\n",
      " [32]\n",
      " [20]\n",
      " [17]\n",
      " [25]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [32]\n",
      " [20]\n",
      " [17]\n",
      " [ 1]\n",
      " [35]\n",
      " [21]\n",
      " [24]\n",
      " [16]\n",
      " [24]\n",
      " [21]\n",
      " [26]\n",
      " [19]\n",
      " [31]\n",
      " [ 1]\n",
      " [13]\n",
      " [30]\n",
      " [17]\n",
      " [ 1]\n",
      " [16]\n",
      " [17]\n",
      " [13]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "X, Y, ix_to_char, vocab_size = load_data('data/game_of_thrones.txt')\n",
    "print(vocab_size)\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data  (1567119, 100, 1) \n",
      "Shape of output data  (1567119, 39)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of input data \", X.shape, \"\\nShape of output data \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model   = create_model(1, X.shape, 256, Y.shape[1], drop_rate = 0.1, activation = 'softmax', mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" your attacks.\n",
      "the more time he spent with them, the more jon despised them.\n",
      "inside, jon hung sword a \"\n",
      "Predictions\n",
      "\" nd she had been the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the starks and she was a sound of the sears of the starks and she was a sound of the sears of the starks and she was a sound of th \"\n"
     ]
    }
   ],
   "source": [
    "#train(model, X, Y, 20, 128, vocab_size)\n",
    "generate_text(model, X, \"Weights/weights-improvement-05-1.5560.hdf5\", ix_to_char, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
