{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported everything we need form Keras, we're all set to go!\n",
    "\n",
    "First, we load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data        = open(filename).read()\n",
    "    data        = data.lower()\n",
    "    \n",
    "    # Find all the unique characters\n",
    "    chars       = sorted(list(set(data)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    vocab_size  = len(chars)\n",
    "    \n",
    "    list_X      = []\n",
    "    list_Y      = []\n",
    "    # Python append is faster than numpy append\n",
    "    for i in range(0, len(data) - SEQ_LENGTH, 1):\n",
    "        seq_in  = data[i : i + SEQ_LENGTH]\n",
    "        seq_out = data[i + SEQ_LENGTH]\n",
    "        list_X.append([char_to_int[char] for char in seq_in])\n",
    "        list_Y.append(char_to_int[seq_out])\n",
    "    \n",
    "    n_patterns  = len(list_X)\n",
    "\n",
    "    X           = np.reshape(list_X, (n_patterns, SEQ_LENGTH, 1))\n",
    "\n",
    "    # Encode output as one-hot vector\n",
    "    Y           = np_utils.to_categorical(list_Y)\n",
    "\n",
    "    return X, Y, int_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions returns an array of sequences from the input text file and the corresponding output for each sequence encoded as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add a function to create our LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(n_layers, input_shape, hidden_dim, n_out, **kwargs):\n",
    "    drop        = kwargs.get('drop_rate', 0.2)\n",
    "    activ       = kwargs.get('activation', 'softmax')\n",
    "    hidden_dim  = int(hidden_dim)\n",
    "    model       = Sequential()\n",
    "    flag        = True \n",
    "\n",
    "    if n_layers == 1:   \n",
    "        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2])) )\n",
    "        model.add( Dropout(drop) )\n",
    "\n",
    "    else:\n",
    "        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2]), return_sequences = True) )\n",
    "        model.add( Dropout(drop) )\n",
    "        for i in range(n_layers - 2):\n",
    "            model.add( LSTM(hidden_dim, return_sequences = True) )\n",
    "            model.add( Dropout(drop) )\n",
    "        model.add( LSTM(hidden_dim) )\n",
    "\n",
    "    model.add( Dense(n_out, activation = activ) )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, X, Y, n_epochs, b_size, vocab_size, **kwargs):    \n",
    "    loss            = kwargs.get('loss', 'categorical_crossentropy')\n",
    "    opt             = kwargs.get('optimizer', 'adam')\n",
    "    \n",
    "    model.compile(loss = loss, optimizer = opt)\n",
    "\n",
    "    filepath        = \"Weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "    callbacks_list  = [checkpoint]\n",
    "    X               = X / float(vocab_size)\n",
    "    model.fit(X, Y, epochs = n_epochs, batch_size = b_size, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function will run the input batchwase n_epochs number of times and it will save the weights to a file whenever there is an improvement. This is taken care of through the callback. <br><br>\n",
    "After the training is done or once you find a loss that you are happy with, you can test how well the model generates text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, X, filename, ix_to_char, vocab_size):\n",
    "    \n",
    "    # Load the weights from the epoch with the least loss\n",
    "    model.load_weights(filename)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "    start   = np.random.randint(0, len(X) - 1)\n",
    "    pattern = np.ravel(X[start]).tolist()\n",
    "\n",
    "    # We seed the model with a random sequence of 100 so it can start predicting\n",
    "    print (\"Seed:\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in pattern]), \"\\\"\")\n",
    "    output = []\n",
    "    for i in range(250):\n",
    "        x           = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x           = x / float(vocab_size)\n",
    "        prediction  = model.predict(x, verbose = 0)\n",
    "        index       = np.argmax(prediction)\n",
    "        result      = index\n",
    "        output.append(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1 : len(pattern)]\n",
    "\n",
    "    print(\"Predictions\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in output]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to either train our test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, ix_to_char, vocab_size = load_data('data/game_of_thrones.txt')\n",
    "print(vocab_size)\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of input data \", X.shape, \"\\nShape of output data \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model   = create_model(1, X.shape, 256, Y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train(model, X, Y, 20, 128, vocab_size)\n",
    "generate_text(model, X, \"Weights/weights-improvement-05-1.5560.hdf5\", ix_to_char, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
