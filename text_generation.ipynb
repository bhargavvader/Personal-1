{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported everything we need form Keras, we're all set to go!\n",
    "\n",
    "First, we load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data        = open(filename).read()\n",
    "    data        = data.lower()\n",
    "    \n",
    "    # Find all the unique characters\n",
    "    chars       = sorted(list(set(data)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    vocab_size  = len(chars)\n",
    "    \n",
    "    list_X      = []\n",
    "    list_Y      = []\n",
    "    # Python append is faster than numpy append\n",
    "    for i in range(0, len(data) - SEQ_LENGTH, 1):\n",
    "        seq_in  = data[i : i + SEQ_LENGTH]\n",
    "        seq_out = data[i + SEQ_LENGTH]\n",
    "        list_X.append([char_to_int[char] for char in seq_in])\n",
    "        list_Y.append(char_to_int[seq_out])\n",
    "    \n",
    "    n_patterns  = len(list_X)\n",
    "\n",
    "    X           = np.reshape(list_X, (n_patterns, SEQ_LENGTH, 1))\n",
    "\n",
    "    # Encode output as one-hot vector\n",
    "    Y           = np_utils.to_categorical(list_Y)\n",
    "\n",
    "    return X, Y, int_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions returns an array of sequences from the input text file and the corresponding output for each sequence encoded as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add a function to create our LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(n_layers, input_shape, hidden_dim, n_out, **kwargs):\n",
    "    drop        = kwargs.get('drop_rate', 0.2)\n",
    "    activ       = kwargs.get('activation', 'softmax')\n",
    "    mode        = kwargs.get('mode', 'train')\n",
    "    hidden_dim  = int(hidden_dim)\n",
    "    model       = Sequential()\n",
    "    flag        = True \n",
    "\n",
    "    if n_layers == 1:   \n",
    "        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2])) )\n",
    "        if mode == 'train':\n",
    "            model.add( Dropout(drop) )\n",
    "\n",
    "    else:\n",
    "        model.add( LSTM(hidden_dim, input_shape = (input_shape[1], input_shape[2]), return_sequences = True) )\n",
    "        if mode == 'train':\n",
    "            model.add( Dropout(drop) )\n",
    "        for i in range(n_layers - 2):\n",
    "            model.add( LSTM(hidden_dim, return_sequences = True) )\n",
    "            if mode == 'train':\n",
    "                model.add( Dropout(drop) )\n",
    "        model.add( LSTM(hidden_dim) )\n",
    "\n",
    "    model.add( Dense(n_out, activation = activ) )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, X, Y, n_epochs, b_size, vocab_size, **kwargs):    \n",
    "    loss            = kwargs.get('loss', 'categorical_crossentropy')\n",
    "    opt             = kwargs.get('optimizer', 'adam')\n",
    "    \n",
    "    model.compile(loss = loss, optimizer = opt)\n",
    "\n",
    "    filepath        = \"Weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "    callbacks_list  = [checkpoint]\n",
    "    X               = X / float(vocab_size)\n",
    "    model.fit(X, Y, epochs = n_epochs, batch_size = b_size, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function will run the input batchwase n_epochs number of times and it will save the weights to a file whenever there is an improvement. This is taken care of through the callback. <br><br>\n",
    "After the training is done or once you find a loss that you are happy with, you can test how well the model generates text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, X, filename, ix_to_char, vocab_size):\n",
    "    \n",
    "    # Load the weights from the epoch with the least loss\n",
    "    model.load_weights(filename)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "    start   = np.random.randint(0, len(X) - 1)\n",
    "    pattern = np.ravel(X[start]).tolist()\n",
    "\n",
    "    # We seed the model with a random sequence of 100 so it can start predicting\n",
    "    print (\"Seed:\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in pattern]), \"\\\"\")\n",
    "    output = []\n",
    "    for i in range(250):\n",
    "        x           = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x           = x / float(vocab_size)\n",
    "        prediction  = model.predict(x, verbose = 0)\n",
    "        index       = np.argmax(prediction)\n",
    "        result      = index\n",
    "        output.append(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1 : len(pattern)]\n",
    "\n",
    "    print(\"Predictions\")\n",
    "    print (\"\\\"\", ''.join([ix_to_char[value] for value in output]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to either train our test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "[[25]\n",
      " [ 1]\n",
      " [43]\n",
      " [39]\n",
      " [38]\n",
      " [31]\n",
      " [ 1]\n",
      " [39]\n",
      " [30]\n",
      " [ 1]\n",
      " [33]\n",
      " [27]\n",
      " [29]\n",
      " [ 1]\n",
      " [25]\n",
      " [38]\n",
      " [28]\n",
      " [ 1]\n",
      " [30]\n",
      " [33]\n",
      " [42]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [25]\n",
      " [ 1]\n",
      " [31]\n",
      " [25]\n",
      " [37]\n",
      " [29]\n",
      " [ 1]\n",
      " [39]\n",
      " [30]\n",
      " [ 1]\n",
      " [44]\n",
      " [32]\n",
      " [42]\n",
      " [39]\n",
      " [38]\n",
      " [29]\n",
      " [43]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [40]\n",
      " [42]\n",
      " [39]\n",
      " [36]\n",
      " [39]\n",
      " [31]\n",
      " [45]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [47]\n",
      " [29]\n",
      " [ 1]\n",
      " [43]\n",
      " [32]\n",
      " [39]\n",
      " [45]\n",
      " [36]\n",
      " [28]\n",
      " [ 1]\n",
      " [43]\n",
      " [44]\n",
      " [25]\n",
      " [42]\n",
      " [44]\n",
      " [ 1]\n",
      " [26]\n",
      " [25]\n",
      " [27]\n",
      " [35]\n",
      " [ 7]\n",
      " [ 1]\n",
      " [31]\n",
      " [25]\n",
      " [42]\n",
      " [29]\n",
      " [28]\n",
      " [ 1]\n",
      " [45]\n",
      " [42]\n",
      " [31]\n",
      " [29]\n",
      " [28]\n",
      " [ 1]\n",
      " [25]\n",
      " [43]\n",
      " [ 1]\n",
      " [44]\n",
      " [32]\n",
      " [29]\n",
      " [ 1]\n",
      " [47]\n",
      " [39]\n",
      " [39]\n",
      " [28]\n",
      " [43]\n",
      " [ 1]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "X, Y, ix_to_char, vocab_size = load_data('data/game_of_thrones.txt')\n",
    "print(vocab_size)\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data  (1605865, 100, 1) \n",
      "Shape of output data  (1605865, 51)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of input data \", X.shape, \"\\nShape of output data \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model   = create_model(1, X.shape, 256, Y.shape[1], mode = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 512/1024 [==============>...............] - ETA: 6s - loss: 3.9382Epoch 00000: loss improved from inf to 3.92387, saving model to Weights/weights-improvement-00-3.9239.hdf5\n",
      "1024/1024 [==============================] - 12s - loss: 3.9239    \n"
     ]
    }
   ],
   "source": [
    "train(model, X[:1024], Y[:1024], 1, 512, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model   = create_model(1, X.shape, 256, Y.shape[1], mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ughter commands us to ride for king's landing at once, to defend the red keep against king renly and \"\n",
      "Predictions\n",
      "\"  the soon of the soon of the wall. \n",
      "\n",
      " the king says the wasl was a soall soile of the sane to the would oe the cialeenn of the sarears. the soon of the wall was a sool to the ther sertanes of the world. \n",
      "\n",
      " the king sassa he was a soall soile of the s \"\n"
     ]
    }
   ],
   "source": [
    "generate_text(model, X, \"Weights/weights-improvement-36-1.7693.hdf5\", ix_to_char, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
